ğŸ“˜ Chapter 02 â€“ OneLake & Lakehouse Architecture

The Heart of Microsoft Fabric

ğŸŒŠ 1ï¸âƒ£ What is OneLake?

OneLake is the central storage system of Microsoft Fabric.

It is:

The OneDrive for enterprise data.

Every workload inside Microsoft Fabric stores data in OneLake.

ğŸ§  Why OneLake Was Created?

Before OneLake:

Each system had its own storage.

Data was copied multiple times.

Storage costs increased.

Governance became complex.

Microsoft solved this by introducing:

âœ… One logical data lake for entire organization
âœ… No duplication required
âœ… Shared across all engines

ğŸ— 2ï¸âƒ£ Logical Structure of OneLake
Tenant
 â””â”€â”€ OneLake
      â”œâ”€â”€ Workspace 1
      â”‚     â”œâ”€â”€ Lakehouse
      â”‚     â”œâ”€â”€ Warehouse
      â”‚     â””â”€â”€ Notebook
      â”œâ”€â”€ Workspace 2
      â””â”€â”€ Workspace 3

Important Concept:

ğŸ”¹ Each organization has one OneLake
ğŸ”¹ Workspaces organize projects
ğŸ”¹ Items (Lakehouse, Warehouse, etc.) store data inside it

ğŸ¢ 3ï¸âƒ£ What is a Lakehouse?

A Lakehouse combines:

Data Lake	Data Warehouse
Cheap storage	Structured analytics
Raw files	SQL tables
Big data	BI optimized

Fabricâ€™s Lakehouse supports:

Files (CSV, Parquet, JSON)

Delta tables

Spark processing

SQL querying

ğŸ”¥ 4ï¸âƒ£ Lakehouse Internal Structure

Inside a Lakehouse:

Lakehouse
 â”œâ”€â”€ Files
 â””â”€â”€ Tables

ğŸ“ Files Section

Used for:

Raw ingestion

Staging data

External data

ğŸ—„ Tables Section

Used for:

Cleaned data

Structured Delta tables

Reporting datasets

ğŸ§ª 5ï¸âƒ£ Step-by-Step Practical Example (Retail Project)

Letâ€™s build your first Lakehouse project.

ğŸ¯ Scenario

A retail company has:

sales.csv

customers.csv

products.csv

Goal:

Create analytics-ready tables.

ğŸŸ¢ Step 1 â€“ Create Workspace

In Fabric portal:

New Workspace â†’ Name: RetailAnalytics

ğŸŸ¢ Step 2 â€“ Create Lakehouse

Inside workspace:

New â†’ Lakehouse â†’ Name: RetailLakehouse


Fabric automatically creates storage in OneLake.

ğŸŸ¢ Step 3 â€“ Upload Raw Files

Go to:

Lakehouse â†’ Files â†’ Upload


Upload:

sales.csv

customers.csv

products.csv

Now stored in:

OneLake/RetailAnalytics/RetailLakehouse/Files/

ğŸŸ¢ Step 4 â€“ Transform Using Notebook (Spark)

Create Notebook inside Lakehouse.

Example Code:
# Load sales data
df_sales = spark.read.csv("Files/sales.csv", header=True, inferSchema=True)

# Basic transformation
df_clean = df_sales.filter(df_sales["revenue"] > 0)

# Save as Delta table
df_clean.write.format("delta").saveAsTable("sales_clean")


What happened?

Read CSV

Cleaned data

Saved as Delta table

Stored in OneLake

Automatically appears in "Tables" section

ğŸŸ¢ Step 5 â€“ Query Using SQL

Open SQL endpoint of Lakehouse.

SELECT region, SUM(revenue)
FROM sales_clean
GROUP BY region;


No data movement.
No duplication.

âš¡ 6ï¸âƒ£ What Makes This Powerful?

All engines read the same data:

Spark

SQL

Power BI

Data Science

Real-Time Analytics

Everything uses:

Delta format inside OneLake

ğŸ”„ 7ï¸âƒ£ Delta Lake Explained Simply

Fabric stores tables in:

Open Delta Lake format

Benefits:

Feature	Meaning
ACID	No partial updates
Time Travel	Query old versions
Schema Evolution	Add columns safely
Fast reads	Optimized storage

Example:

SELECT * FROM sales_clean VERSION AS OF 2;


You can query older versions.

ğŸ§¬ 8ï¸âƒ£ Medallion Architecture in Fabric

Fabric supports:

Bronze â†’ Silver â†’ Gold pattern

ğŸŸ¤ Bronze (Raw)

Raw ingestion.

Example:

sales.csv

customers.csv

âšª Silver (Cleaned)

Cleaned, validated data.

Example:

sales_clean

customers_clean

ğŸŸ¡ Gold (Business Ready)

Aggregated tables.

Example:

CREATE TABLE sales_summary AS
SELECT region, SUM(revenue) total_revenue
FROM sales_clean
GROUP BY region;

ğŸ¯ 9ï¸âƒ£ Direct Lake Mode (Revolutionary Feature)

With:

Power BI

Traditional approach:

Import data â†’ Create model â†’ Refresh needed.

Fabric approach:

Power BI reads directly from Delta table in OneLake.

No import.
No refresh.
Ultra-fast.

ğŸ” ğŸ”Ÿ Security in OneLake

Uses:

Microsoft Entra ID

Supports:

Workspace-level access

Table-level permissions

Row-level security

Data masking

Example:

Restrict HR salary data to HR team only.

ğŸ— 11ï¸âƒ£ Physical Storage Behind the Scene

Internally:

Built on Azure Data Lake Gen2

Managed fully by Fabric

You never manage storage account manually

ğŸ’° 12ï¸âƒ£ Cost Efficiency Example

Without Fabric:

Separate storage

Separate Synapse pool

Separate Power BI capacity

With Fabric:

One storage

Shared compute

Unified capacity

Lower cost.

ğŸ“Š 13ï¸âƒ£ End-to-End Flow Summary
Upload CSV
     â†“
Store in Files
     â†“
Spark Transform
     â†“
Save as Delta Table
     â†“
SQL Query
     â†“
Power BI Direct Lake Report


Single platform.
Single storage.
Single security.

ğŸ§  14ï¸âƒ£ Real Enterprise Use Case
Smart City Project

Data sources:

Traffic sensors

Weather API

Pollution monitoring

CCTV logs

Steps:

Data Factory ingests

Stored in Bronze

Cleaned in Silver

Aggregated in Gold

Power BI dashboard

AI prediction model runs on same data

All inside Fabric.

ğŸ“Œ 15ï¸âƒ£ Key Takeaways
Concept	Why Important
OneLake	Single source of truth
Lakehouse	Flexible analytics
Delta format	Reliable data
Medallion	Structured pipeline
Direct Lake	Real-time reporting
ğŸ“ What You Learned in This Chapter

You now understand:

OneLake architecture

Lakehouse structure

Files vs Tables

Delta Lake

Medallion architecture

Direct Lake mode

Real-world implementation

You are now thinking like a Fabric Architect.
